# Coders-Strike-Back
I did a little research on this puzzle to try to understand how many tests I need to pass in total and to pre-visualize the time to pass on it. So we need to pass from wood to Bronze then to Gold and in the end to Legend. My timetable was so filled that I could not get a whole free week to finish this test. I worked mainly on the 15th, 16th, 19th, 20th, and from the 22nd evening to the 23rd morning.

It was the first time I used CodinGame to resolve puzzles. I signed up Monday 12 when I received the test and followed its tutorial to finish the test until Wood 2.
The first two questions were really simple. I just need to change the name of the variables.

Wood 2 asked for the change of thrust and in pseudocode, it provided the way to do it: when the angle is bigger or smaller than 90, we set thrust to 0, otherwise thrust = 100.
Wood 1 added a “BOOST”. I first only changed thrust to “BOOST” and obviously, it’s not enough. We can use “BOOST” only one time, therefore, when to use it is a question to be resolved. The first thing that occurred to me was the use of “BOOST” when the pod is aligned with the direction of the checkpoint and the distance is far enough to do the “BOOST”. Therefore, I asked the pod to “BOOST” when the angle is 0 and the pod is 2000 units away from the checkpoint.

Bronze added a collision between the pods but I had no idea how to use it to optimize the movement of the pod. Therefore I continued to optimize the movement of the pod following the idea before.

The first thing to play with is the speed of the pod. If the pod moves too fast when it is close to the checkpoint, it will advance still a lot because of the inertance. Hence we need to slow down the pod. The closer the pod to the checkpoint, the slower the pod should be. I thus multiply the thrust with the (dist/radius to slow down) which is between [0:1]. After several tests, 4 times the radius of the checkpoint works best.

We can also slow down the pod when the angle is too big. We’ve already decided that if the angle is bigger than 90, we set thrust to 0. But when the angle is between 90 and 0, we can also slow down the pod to avoid the insurance. I first set an AngleMin to 5 degrees so that the thrust of the pod will always be max. And for the angle between 5 to 90, the bigger the angle is, the slower the pod is, so I multiplied the thrust with the (1 - (angle/90)) which is also between (0:1].

At first, I multiplied these two coefficients together, but I found that this may slow down too much the pod if the pod doesn’t get to the checkpoint with a degree less than AngleMin, So I split them and slow down the pod regarding distance only when the pod arrives at checkpoint straitly. This part took me almost 2 hours.

The second thing to complete is the moment to use “BOOST”. In Wood 1 I used it when I found a straight direction and a distance far enough. The better way may be to use it between two checkpoints whose distance is max. To do this, I need to know the distance between all the checkpoints. Therefore I designed a function to save all the checkpoints during the first lap and with these positions of checkpoints, I can calculate the distance between them then get the maxDistance. However, sometimes I found the pod doesn’t speed up if the checkpoints are too close to each other and the pod needs to rotate frequently. So I give 2 degrees of freedom to the pod to accelerate and since this may be also applied to the part of slow down, I changed AngleMin to 1 degree. With enough distance and the right direction, the pod accelerated well at the moment I wanted. This part took me almost 2H too. It was not difficult to design the method but to do this part I created a class of type Point to save the position of checkpoints, which took more time than I thought.

These two parts were not sufficient to get to the next level, so I thought maybe I need to ask my pod to turn faster. In the beginning, I didn’t find a good way to change the destination position. I added 15 degrees to the angle to try to calculate the new position of the destination but this method didn’t return a positive result. I also tried to find the difference of angle between the moment before and this moment to know the angle the pod turned and calculate the new destination point by using this angle and the distance, but the movement of the pod became unstable and slower in this case. In the end, I found a tutorial on Steering Behaviors from the website (https://gamedevelopment.tutsplus.com/series/understanding-steering-behaviors--gamedev-12732). By following its explanation, I added a velocity to the destination and it turned out to work well. Regarding functions such as normalize that need a precision of float instead of int, I changed my class Point to adapt with it. This part is the most difficult part I faced during the Bronze level and it took almost all day long.

To decrease the complexity of the code, I used the distance given by the program directly to get the maxDistance instead of calculating by myself.

With this version of code, I got to the Gold level directly. From the Gold level to legend level is different from what we code before. The inputs and the rules have been changed so that we have 2 pods now. I tested with the initial code to check the rule, it turns out once one of my pods arrives at the final, I win. Therefore the idea is simple, use one pod like the one who finishes the laps, and use another to hinder my opponent.

The first thing I did was reuse my method before checking the performance of my code. It works well but is too slow compared with the opponent. So the problem is how to find the best next step. I would like to use the genetic algorithm to simulate several solutions to get the best next step. I first created a class Pod to represent each pod with its information and a class Checkpoint for each Checkpoint, which turned out to be useless that I deleted in the end. I then followed the description in “expert rule” to write the functions for each step, which includes “rotate”, “accelerate”, “move”, “friction”, and “round”. In “move” by considering the problem of collision and rebound, I wrote also the function to calculate the minTime of collision between 2 pods and the rebound after the collision. To know which step I did is better, I need to evaluate my steps. Therefore I evaluate the score of each possible step by calculating the distance between my pods with the opponents. So for each turn of simulation, I evaluate them and save the score. In the beginning, I didn’t take into consideration the movement of my pod whose mission is to bother my opponent, and obviously, at that moment all my pods tried to get to the end. Therefore I added the score of my second pod and I decided that running farther than my opponent is more important than bothering them.

After having this global idea of simulation, I began to think about how my solution should be. The information I can control is “boost”, “shield”, “re-calculate the output destination to ask my pods to turn faster”, “thrust”. So I created a class named “Movement” to save this information. For each solution I did, I wanted it to simulate not only one step but several steps to predict the movement. Therefore for each solution, I saved several steps and for each step, I provided a vector to save the movement of each pod. To get the value of the movement, I wrote a function “Randomize” which provides the value randomly for my movements.
Then I began to think about how my program works in each loop. The first thing to do is update the pod from the input. Then I began to simulate the solutions and in the end, I converted my best solution into output.

During the test, I found my program has a low performance. Therefore, to optimize my program, I tried several operations including optimizing the function “rand”, asking my pod boost at first if possible(this idea came out by observing the movement of the opponent), re-organize the structure of my classes, re-write my functions, consider the time of each step to maximize the possible simulation, etc. With all these optimizations, I still can not beat the boss of Gold and I’m ranked 11/6673 in Gold level.
All the parts of Gold took me almost 2.5 days. The optimization after deciding on the idea takes a long time since I need to think about whether somewhere is possible to be optimized all the time to increase my rank. During the implementation, the part of the rebound is where I got no idea how to do it at the beginning. The part of the simulation is more complex than I thought before and it also took a long time to optimize little by little.

To get to the next level, the things I didn’t do include taking into consideration the movement of my opponent, calculating the possible better steps instead of just giving a value randomly, calculating the possible ways to optimize my movements when I tried to recalculate the solutions. I know just a little about the genetic algorithms that I just inspired from this idea, maybe there are still some useful notions for my program.

I think this puzzle is really interesting and complex to implement since we have many possibilities to optimize our program. When I was in Bronze level, I’ve no idea how to play with the collision between pods at all, and when I jumped from Bronze to Silver(Which I thought after Bronze is directly Gold because of my research), It provided a new parameter “Shield” which explains the use of collision. However, when I tried to add this parameter in my program and test whether it works. I got to Gold level automatically and since Gold level provides a different group of inputs, All the code I wrote before seems useless and it turns out I truly didn't use them in the end even though I tried to re-use them at the beginning, which is a little sad.
